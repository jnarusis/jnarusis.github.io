<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Local LLM Lab - Justin Narusis">
  <title>Local LLM Lab</title>
  <link rel="stylesheet" href="style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&display=swap">
</head>
<body>
  <div class="layout">
    <aside class="sidebar" role="navigation" aria-label="Page Navigation">
      <nav>
        <ul>
          <li><a href="#overview">Overview</a></li>
          <li><a href="#setup">Setup & Process</a></li>
          <li><a href="#training">Fine-Tuning & Chatbot</a></li>
          <li><a href="#phi2">Phi-2 Deployment</a></li>
          <li><a href="#issues">Challenges & Fixes</a></li>
          <li><a href="#skills">Skills Demonstrated</a></li>
          <li><a href="index.html#portfolio">← Back to Portfolio</a></li>
        </ul>
      </nav>
    </aside>

    <main class="main-content">
      <div class="banner">
        <img src="banner.jpg" alt="Portfolio Banner">
      </div>

      <section id="overview" class="section">
        <h1>Local LLM Lab</h1>
        <p>Ongoing Project — Deploying and fine-tuning quantized large language models (LLMs) entirely on local CPU hardware using open-source tools.</p>
        <div class="image-frame">
          <a href="images/llm-lab/tinyllama-hello-response.png" target="_blank">
            <img src="images/llm-lab/tinyllama-hello-response.png" alt="TinyLLaMA Hello Response" class="badge-image">
          </a>
          <p class="image-caption">TinyLLaMA sample response after successful deployment</p>
        </div>
      </section>

      <section id="setup" class="section">
        <h2>Setup & Process</h2>
        <ul>
          <li>Compiled <code>llama.cpp</code> from source using CMake</li>
          <li>Installed system libraries such as <code>libcurl4-openssl-dev</code> and created Python virtual environments</li>
          <li>Authenticated Hugging Face CLI and manually downloaded models via <code>wget</code> with secure tokens</li>
          <li>Launched models using <code>llama-cli</code> and explored prompt formatting with and without templates</li>
        </ul>
        <div class="image-frame">
          <a href="images/llm-lab/tinyllama-lora-setup.png" target="_blank">
            <img src="images/llm-lab/tinyllama-lora-setup.png" alt="TinyLLaMA Setup Screenshot" class="badge-image">
          </a>
          <p class="image-caption">Model launched via llama.cpp CLI on Kubuntu 24.04 with appropriate flags</p>
        </div>
      </section>

      <section id="training" class="section">
        <h2>Fine-Tuning & Chatbot</h2>
        <ul>
          <li>Used Hugging Face Transformers and PEFT to fine-tune TinyLLaMA using LoRA adapters on CPU</li>
          <li>Created a dataset of instruction/response pairs in JSON format</li>
          <li>Trained LoRA adapter over multiple epochs and exported adapter files with <code>save_pretrained</code></li>
          <li>Tested adapter loading and validated output responses</li>
          <li>Built an interactive CLI chatbot and added a KDE Application Menu launcher</li>
        </ul>
        <div class="image-frame">
          <a href="images/llm-lab/tinyllama-lora-training.png" target="_blank">
            <img src="images/llm-lab/tinyllama-lora-training.png" alt="LoRA Training Screenshot" class="badge-image">
          </a>
          <p class="image-caption">LoRA fine-tuning log showing completion on CPU-only machine</p>
        </div>
        <div class="image-frame">
          <a href="images/llm-lab/tinyllama-lora-dataset.png" target="_blank">
            <img src="images/llm-lab/tinyllama-lora-dataset.png" alt="LoRA Dataset Format" class="badge-image">
          </a>
          <p class="image-caption">JSON format of instruction-tuned dataset used during LoRA training</p>
        </div>
        <div class="image-frame">
          <a href="images/llm-lab/tinyllama-lora-final-response.png" target="_blank">
            <img src="images/llm-lab/tinyllama-lora-final-response.png" alt="Final Response Test" class="badge-image">
          </a>
          <p class="image-caption">Model answering questions post-LoRA tuning, verifying adapter behavior</p>
        </div>
        <div class="image-frame">
          <a href="images/llm-lab/tinyllama-cli-chatbot.png" target="_blank">
            <img src="images/llm-lab/tinyllama-cli-chatbot.png" alt="TinyLLaMA CLI Chatbot" class="badge-image">
          </a>
          <p class="image-caption">Custom CLI chatbot script interacting with fine-tuned TinyLLaMA</p>
        </div>
      </section>

      <section id="phi2" class="section">
        <h2>Phi-2 Deployment</h2>
        <ul>
          <li>Downloaded quantized <code>phi-2.Q4_K_M.gguf</code> using authenticated <code>wget</code></li>
          <li>Launched Phi-2 via <code>llama-cli</code> using the <code>--interactive-first</code> flag to improve behavior</li>
          <li>Modified prompt format to produce natural language answers from base model</li>
        </ul>
        <div class="image-frame">
          <a href="images/llm-lab/phi2-hello-response.png.png" target="_blank">
            <img src="images/llm-lab/phi2-hello-response.png.png" alt="Phi-2 Hello Response Screenshot" class="badge-image">
          </a>
          <p class="image-caption">Phi-2 model responding in plain language after prompt refinement</p>
        </div>
      </section>

      <section id="issues" class="section">
        <h2>Challenges & Fixes</h2>
        <ul>
          <li>⚠️ Broken <code>curl</code> downloads → switched to <code>wget</code> with Hugging Face token headers</li>
          <li>⚠️ Makefile deprecated → used CMake build path for <code>llama.cpp</code></li>
          <li>⚠️ LoRA adapter not saving → added <code>model.save_pretrained()</code> explicitly</li>
          <li>⚠️ Launch errors with <code>llama-simple-chat</code> → used <code>llama-cli</code> for compatibility</li>
          <li>⚠️ HTML-style or malformed output → resolved via <code>--interactive-first</code> and prompt tuning</li>
        </ul>
      </section>

      <section id="skills" class="section">
        <h2>Skills Demonstrated</h2>
        <ul>
          <li>System-level installation and compilation (Ubuntu, CMake, CLI troubleshooting)</li>
          <li>Quantized LLM management with GGUF + llama.cpp</li>
          <li>LoRA training and adapter evaluation with PEFT</li>
          <li>Prompt engineering and output refinement</li>
          <li>CLI scripting, launcher creation, and desktop integration (Konsole, KDE)</li>
        </ul>
      </section>

      <footer class="footer">
        <p><a href="index.html">&larr; Back to Main Site</a></p>
      </footer>
    </main>
  </div>
</body>
</html>
